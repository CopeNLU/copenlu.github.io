<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CopeNLU on CopeNLU</title>
    <link>https://copenlu.github.io/</link>
    <description>Recent content in CopeNLU on CopeNLU</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>CiteWorth: Cite-Worthiness Detection for Improved Scientific Document Understanding</title>
      <link>https://copenlu.github.io/publication/2021_acl_wright_citeworth/</link>
      <pubDate>Thu, 06 May 2021 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/publication/2021_acl_wright_citeworth/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Is Sparse Attention more Interpretable?</title>
      <link>https://copenlu.github.io/publication/2021_acl_meister_sparse/</link>
      <pubDate>Thu, 06 May 2021 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/publication/2021_acl_meister_sparse/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Paper Accepted to IJCAI 2021</title>
      <link>https://copenlu.github.io/talk/2021_04_ijcai/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/talk/2021_04_ijcai/</guid>
      <description>&lt;p&gt;A paper by CopeNLU author is accepted to appear at IJCAI 2021. The paper studies how to perform complex claim verification on naturally occurring political claims with multiple hops over evidence chunks.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://copenlu.github.io/publication/2021_ijcai_ostrowski/&#34;&gt;Multi-Hop Fact Checking of Political Claims&lt;/a&gt;.
&lt;a href=&#34;https://copenlu.github.io/authors/wojciech-ostrowski/&#34;&gt;Wojciech Ostrowski&lt;/a&gt;,  &lt;a href=&#34;https://copenlu.github.io/authors/arnav-arora/&#34;&gt;Arnav Arora&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/pepa-atanasova/&#34;&gt;Pepa Atanasova&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/isabelle-augenstein/&#34;&gt;Isabelle Augenstein&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi-Hop Fact Checking of Political Claims</title>
      <link>https://copenlu.github.io/publication/2021_ijcai_ostrowski/</link>
      <pubDate>Fri, 30 Apr 2021 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/publication/2021_ijcai_ostrowski/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quantifying Gender Bias Towards Politicians in Cross-Lingual Language Models</title>
      <link>https://copenlu.github.io/publication/2021_arxiv_stanczak/</link>
      <pubDate>Thu, 15 Apr 2021 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/publication/2021_arxiv_stanczak/</guid>
      <description></description>
    </item>
    
    <item>
      <title>2 Papers Accepted to ACL 2021</title>
      <link>https://copenlu.github.io/talk/2021_04_acl/</link>
      <pubDate>Mon, 05 Apr 2021 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/talk/2021_04_acl/</guid>
      <description>&lt;p&gt;2 papers by CopeNLU authors are accepted to appear at ACL 2021. One paper is on interpretability, examining how sparsity affects our ability to use attention as an explainability tool; whereas the other one is on scientific document understanding, introducing a new dataset for the task of cite-worthiness detection in scientific articles.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://copenlu.github.io/publication/2021_acl_meister_sparse/&#34;&gt;Is Sparse Attention more Interpretable?&lt;/a&gt;
&lt;a href=&#34;https://copenlu.github.io/authors/clara-meister/&#34;&gt;Clara Meister&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/stefan-lazov/&#34;&gt;Stefan Lazov&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/isabelle-augenstein/&#34;&gt;Isabelle Augenstein&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/ryan-cotterell/&#34;&gt;Ryan Cotterell&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://copenlu.github.io/publication/2021_acl_wright_citeworth/&#34;&gt;CiteWorth: Cite-Worthiness Detection for Improved Scientific Document Understanding&lt;/a&gt;.
&lt;a href=&#34;https://copenlu.github.io/authors/dustin-wright/&#34;&gt;Dustin Wright&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/isabelle-augenstein/&#34;&gt;Isabelle Augenstein&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Primer on Contrastive Pretraining in Language Processing: Methods, Lessons Learned and Perspectives</title>
      <link>https://copenlu.github.io/publication/2021_arxiv_rethmeier/</link>
      <pubDate>Thu, 25 Feb 2021 00:00:00 +0100</pubDate>
      
      <guid>https://copenlu.github.io/publication/2021_arxiv_rethmeier/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ALPS 2021 tutorial &#39;Explainability for NLP&#39;</title>
      <link>https://copenlu.github.io/post/explainability_tutorial/</link>
      <pubDate>Thu, 28 Jan 2021 00:00:00 +0100</pubDate>
      
      <guid>https://copenlu.github.io/post/explainability_tutorial/</guid>
      <description>&lt;p&gt;We gave a tutorial on &amp;lsquo;Explainability for NLP&amp;rsquo; at the first ALPS (Advanced Language Processing) winter school: &lt;a href=&#34;http://lig-alps.imag.fr/index.php/schedule/&#34; target=&#34;_blank&#34;&gt;http://lig-alps.imag.fr/index.php/schedule/&lt;/a&gt;
The tutorial introduces the concepts of &amp;lsquo;model understanding&amp;rsquo; as well as &amp;lsquo;decision understanding&amp;rsquo; and provides examples of approaches from the areas of fact checking and text classification.&lt;/p&gt;

&lt;p&gt;Exercises for both model understanding and decision understanding are available here: &lt;a href=&#34;https://github.com/copenlu/ALPS_2021&#34; target=&#34;_blank&#34;&gt;https://github.com/copenlu/ALPS_2021&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Does Typological Blinding Impede Cross-Lingual Sharing?</title>
      <link>https://copenlu.github.io/publication/2021_eacl_bjerva/</link>
      <pubDate>Thu, 28 Jan 2021 00:00:00 +0100</pubDate>
      
      <guid>https://copenlu.github.io/publication/2021_eacl_bjerva/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Paper Accepted to EACL 2021</title>
      <link>https://copenlu.github.io/talk/2021_01_eacl/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0100</pubDate>
      
      <guid>https://copenlu.github.io/talk/2021_01_eacl/</guid>
      <description>&lt;p&gt;A paper by CopeNLU author is accepted to appear at EACL 2021. The paper aims to bridge the gap between high- and low-resource languages by investigating to what degree cross-lingual models share structural information about languages.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://copenlu.github.io/publication/2021_EACL_Bjerva/&#34;&gt;Does Typological Blinding Impede Cross-Lingual Sharing?&lt;/a&gt;.
&lt;a href=&#34;https://copenlu.github.io/authors/johannes-bjerva/&#34;&gt;Johannes Bjerva&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/isabelle-augenstein/&#34;&gt;Isabelle Augenstein&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Longitudinal Citation Prediction using Temporal Graph Neural Networks</title>
      <link>https://copenlu.github.io/publication/2020_arxiv_holm/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0100</pubDate>
      
      <guid>https://copenlu.github.io/publication/2020_arxiv_holm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multi-Sense Language Modelling</title>
      <link>https://copenlu.github.io/publication/2020_arxiv_lekkas/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0100</pubDate>
      
      <guid>https://copenlu.github.io/publication/2020_arxiv_lekkas/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Positions available in context of Sapere Aude Research Leader Fellowship on Explainable Stance Detection</title>
      <link>https://copenlu.github.io/talk/2020_10_phd/</link>
      <pubDate>Thu, 19 Nov 2020 00:00:00 +0100</pubDate>
      
      <guid>https://copenlu.github.io/talk/2020_10_phd/</guid>
      <description>&lt;p&gt;Two PhD fellowships and two postdoc positions on explainable stance detection are available in CopeNLU. The PhD fellowships and one of the postdoc positions are offered in the context of a &lt;a href=&#34;https://dff.dk/en/grants/research-leaders-2020/researchleader-14&#34;&gt;DFF Sapere Aude research leader fellowship&lt;/a&gt; on `Learning to Explain Attitudes on Social Media (EXPANSE)Â´. Sapere Aude is a program by the &lt;a href=&#34;https://dff.dk/en&#34;&gt;Independent Research Fund Denmark (DFF)&lt;/a&gt; to support the most talented younger researchers in Denmark with funding for blue-skies research to build up or expand their research groups.&lt;/p&gt;

&lt;p&gt;The EXPANSE project studies attitudes voiced on social media, examining what is said, and explaining it by examining why, how and by whom attitudes are stated. Currently, the only criterion commonly taken into account when researching and developing not just such stance detection, but Natural Language Processing models in general, is predictive performance, e.g. how well models can predict labels such as &amp;lsquo;positive&amp;rsquo;, &amp;lsquo;negative&amp;rsquo; or &amp;lsquo;neutral&amp;rsquo;. This does not provide any insights into why and how models arrive at certain predictions, which is crucial for utilising predictions for decision making. By contrast, this project will examine explainability as a success criterion, in an interdisciplinary approach which combines Natural Language Processing research with sociological theories.&lt;/p&gt;

&lt;p&gt;In addition to the principle investigator, the two PhD students and the postdoc, the project team will also include interdisciplinary collaborators from sociology.
More information about the project can also be found in &lt;a href=&#34;https://dff.dk/en/grants/research-leaders-2020/researchleader-14&#34;&gt;the official announcement on DFF&amp;rsquo;s website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The other available postdoc position is offered in the context of a project on researching explainable NLP methods for educational technologies.&lt;/p&gt;

&lt;p&gt;Candidates are expected to hold a Master&amp;rsquo;s degree in computer science or a related relevant area or be near completion for one. There are no restrictions on citizenship, and a language certificate is not required at application time.
Candidates from traditionally underrepresented minorities in natural language processing are particularly encouraged to apply.&lt;/p&gt;

&lt;p&gt;Read more about reasons to join us &lt;a href=&#34;https://copenlu.github.io/post/why-ucph/&#34;&gt;here&lt;/a&gt;. Before applying, you are welcome to get in touch informally if you have questions about the call. The official call for PhD positions and application link can be found &lt;a href=&#34;https://employment.ku.dk/phd/?show=153856&#34;&gt;here&lt;/a&gt;; the application deadline is 6 May 2021. Note that the other PhD position as well as the postdoc position on the project have already been filled.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>EMNLP 2020 Beer Garden Meetup</title>
      <link>https://copenlu.github.io/post/eth-ucph-party/</link>
      <pubDate>Wed, 18 Nov 2020 00:00:00 +0100</pubDate>
      
      <guid>https://copenlu.github.io/post/eth-ucph-party/</guid>
      <description>&lt;p&gt;Yes, we all have planned to be under palm trees of Punta Cana now and to sip drinks with umbrellas. Let&amp;rsquo;s make a new plan: beer garden on Thursday evening (19:30 CET). All ETH Rycolab and UCPH CopeNLU research group members &amp;amp; friends are invited to join our Gather.Town beer garden to mingle with one another. Sign up &lt;a href=&#34;https://docs.google.com/forms/d/e/1FAIpQLSdXXHt_VRtNEvy_z5CYQsD14aMbsV-KXfI6-p0aowyFkVEIpw/viewform?vc=0&amp;amp;c=0&amp;amp;w=1&amp;amp;flr=0&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; to get the invitation link. The number of spots is limited!&lt;/p&gt;



&lt;div class=&#34;gallery&#34;&gt;

  
  
  
  
    
    
    
    
    
      
    
      
    
    
  &lt;a data-fancybox=&#34;gallery-gallery&#34; href=&#34;https://copenlu.github.io/post/eth-ucph-party/gallery/eth.png&#34; &gt;
  &lt;img src=&#34;https://copenlu.github.io/post/eth-ucph-party/gallery/eth.png&#34; alt=&#34;&#34;&gt;
  &lt;/a&gt;
  
    
    
    
    
    
      
    
      
    
    
  &lt;a data-fancybox=&#34;gallery-gallery&#34; href=&#34;https://copenlu.github.io/post/eth-ucph-party/gallery/ku_co_uk_v.jpg&#34; &gt;
  &lt;img src=&#34;https://copenlu.github.io/post/eth-ucph-party/gallery/ku_co_uk_v.jpg&#34; alt=&#34;&#34;&gt;
  &lt;/a&gt;
  

  
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>University of Copenhagen Participation in TREC Health Misinformation Track 2020</title>
      <link>https://copenlu.github.io/publication/2020_trec_lima/</link>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0100</pubDate>
      
      <guid>https://copenlu.github.io/publication/2020_trec_lima/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
